# AIåº”ç”¨é¡¹ç›®å®æˆ˜

ç²¾é€‰10ä¸ªAIåº”ç”¨é¡¹ç›®ï¼Œä»ç®€å•åˆ°å¤æ‚ï¼ŒåŒ…å«å®Œæ•´ä»£ç å’Œå®ç°æ€è·¯ã€‚

## ğŸ“‹ é¡¹ç›®åˆ—è¡¨

### åˆçº§é¡¹ç›®ï¼ˆ1-2å¤©ï¼‰
1. [AIèŠå¤©æœºå™¨äºº](#é¡¹ç›®1-aièŠå¤©æœºå™¨äºº)
2. [æ™ºèƒ½æ–‡æ¡£æ‘˜è¦](#é¡¹ç›®2-æ™ºèƒ½æ–‡æ¡£æ‘˜è¦)
3. [AIå›¾ç‰‡æè¿°ç”Ÿæˆå™¨](#é¡¹ç›®3-aiå›¾ç‰‡æè¿°ç”Ÿæˆå™¨)

### ä¸­çº§é¡¹ç›®ï¼ˆ3-5å¤©ï¼‰
4. [AIçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ](#é¡¹ç›®4-çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ)
5. [æ™ºèƒ½ä»£ç å®¡æŸ¥å·¥å…·](#é¡¹ç›®5-ä»£ç å®¡æŸ¥å·¥å…·)
6. [AIæ–‡ç« ç”Ÿæˆå™¨](#é¡¹ç›®6-æ–‡ç« ç”Ÿæˆå™¨)

### é«˜çº§é¡¹ç›®ï¼ˆ1-2å‘¨ï¼‰
7. [å¤šæ¨¡æ€AIåŠ©æ‰‹](#é¡¹ç›®7-å¤šæ¨¡æ€aiåŠ©æ‰‹)
8. [AI Agentä»»åŠ¡ç³»ç»Ÿ](#é¡¹ç›®8-ai-agentç³»ç»Ÿ)
9. [ä¼ä¸šçº§RAGå¹³å°](#é¡¹ç›®9-ragå¹³å°)
10. [AIå¼€å‘å·¥å…·é“¾](#é¡¹ç›®10-aiå¼€å‘å·¥å…·é“¾)

---

## é¡¹ç›®1: AIèŠå¤©æœºå™¨äºº

### æŠ€æœ¯æ ˆ
- React + TypeScript
- OpenAI API
- Tailwind CSS

### åŠŸèƒ½ç‰¹ç‚¹
- å®æ—¶å¯¹è¯
- å¯¹è¯å†å²
- Markdownæ¸²æŸ“
- æµå¼è¾“å‡º

### å®Œæ•´ä»£ç 

#### 1. é¡¹ç›®ç»“æ„
```
ai-chatbot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ChatMessage.tsx
â”‚   â”‚   â”œâ”€â”€ ChatInput.tsx
â”‚   â”‚   â””â”€â”€ ChatWindow.tsx
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useChat.ts
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ chat.ts
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ openai.ts
â”‚   â”œâ”€â”€ App.tsx
â”‚   â””â”€â”€ main.tsx
â”œâ”€â”€ .env
â””â”€â”€ package.json
```

#### 2. ç±»å‹å®šä¹‰

```typescript
// types/chat.ts
export interface Message {
  id: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date;
}

export interface ChatConfig {
  model: string;
  temperature: number;
  maxTokens: number;
}
```

#### 3. OpenAIå·¥å…·å‡½æ•°

```typescript
// utils/openai.ts
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true, // ä»…ç”¨äºæ¼”ç¤ºï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥ä½¿ç”¨åç«¯
});

export const sendMessage = async (
  messages: Message[],
  onChunk?: (text: string) => void
): Promise<string> => {
  const stream = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: messages.map(m => ({
      role: m.role,
      content: m.content,
    })),
    stream: true,
  });

  let fullResponse = '';

  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || '';
    fullResponse += content;
    onChunk?.(content);
  }

  return fullResponse;
};
```

#### 4. Chat Hook

```typescript
// hooks/useChat.ts
import { useState, useCallback } from 'react';
import { Message } from '../types/chat';
import { sendMessage } from '../utils/openai';

export const useChat = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [streamingMessage, setStreamingMessage] = useState('');

  const addMessage = useCallback((role: 'user' | 'assistant', content: string) => {
    const message: Message = {
      id: crypto.randomUUID(),
      role,
      content,
      timestamp: new Date(),
    };
    setMessages(prev => [...prev, message]);
    return message;
  }, []);

  const sendUserMessage = useCallback(async (content: string) => {
    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    const userMessage = addMessage('user', content);
    
    setIsLoading(true);
    setStreamingMessage('');

    try {
      // å‘é€åˆ°OpenAIå¹¶è·å–æµå¼å“åº”
      const response = await sendMessage(
        [...messages, userMessage],
        (chunk) => {
          setStreamingMessage(prev => prev + chunk);
        }
      );

      // æ·»åŠ AIå›å¤
      addMessage('assistant', response);
      setStreamingMessage('');
    } catch (error) {
      console.error('å‘é€æ¶ˆæ¯å¤±è´¥:', error);
      addMessage('assistant', 'æŠ±æ­‰ï¼Œå‡ºç°äº†é”™è¯¯ã€‚è¯·ç¨åå†è¯•ã€‚');
    } finally {
      setIsLoading(false);
    }
  }, [messages, addMessage]);

  const clearChat = useCallback(() => {
    setMessages([]);
    setStreamingMessage('');
  }, []);

  return {
    messages,
    isLoading,
    streamingMessage,
    sendMessage: sendUserMessage,
    clearChat,
  };
};
```

#### 5. èŠå¤©æ¶ˆæ¯ç»„ä»¶

```typescript
// components/ChatMessage.tsx
import React from 'react';
import ReactMarkdown from 'react-markdown';
import { Message } from '../types/chat';

interface ChatMessageProps {
  message: Message;
  isStreaming?: boolean;
}

export const ChatMessage: React.FC<ChatMessageProps> = ({ message, isStreaming }) => {
  const isUser = message.role === 'user';

  return (
    <div className={`flex ${isUser ? 'justify-end' : 'justify-start'} mb-4`}>
      <div
        className={`max-w-[70%] rounded-lg px-4 py-2 ${
          isUser
            ? 'bg-blue-500 text-white'
            : 'bg-gray-200 text-gray-800'
        }`}
      >
        {isUser ? (
          <p className="whitespace-pre-wrap">{message.content}</p>
        ) : (
          <div className="prose prose-sm max-w-none">
            <ReactMarkdown>{message.content}</ReactMarkdown>
          </div>
        )}
        {isStreaming && (
          <span className="inline-block w-2 h-4 ml-1 bg-current animate-pulse" />
        )}
      </div>
    </div>
  );
};
```

#### 6. è¾“å…¥ç»„ä»¶

```typescript
// components/ChatInput.tsx
import React, { useState, KeyboardEvent } from 'react';

interface ChatInputProps {
  onSend: (message: string) => void;
  disabled?: boolean;
}

export const ChatInput: React.FC<ChatInputProps> = ({ onSend, disabled }) => {
  const [input, setInput] = useState('');

  const handleSend = () => {
    if (input.trim() && !disabled) {
      onSend(input.trim());
      setInput('');
    }
  };

  const handleKeyPress = (e: KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  return (
    <div className="flex gap-2 p-4 border-t">
      <textarea
        value={input}
        onChange={(e) => setInput(e.target.value)}
        onKeyPress={handleKeyPress}
        placeholder="è¾“å…¥æ¶ˆæ¯... (Shift+Enter æ¢è¡Œ)"
        disabled={disabled}
        className="flex-1 p-2 border rounded-lg resize-none focus:outline-none focus:ring-2 focus:ring-blue-500"
        rows={3}
      />
      <button
        onClick={handleSend}
        disabled={disabled || !input.trim()}
        className="px-6 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:bg-gray-300 disabled:cursor-not-allowed"
      >
        å‘é€
      </button>
    </div>
  );
};
```

#### 7. ä¸»åº”ç”¨

```typescript
// App.tsx
import React, { useEffect, useRef } from 'react';
import { useChat } from './hooks/useChat';
import { ChatMessage } from './components/ChatMessage';
import { ChatInput } from './components/ChatInput';

function App() {
  const { messages, isLoading, streamingMessage, sendMessage, clearChat } = useChat();
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages, streamingMessage]);

  return (
    <div className="flex flex-col h-screen bg-gray-50">
      {/* Header */}
      <div className="bg-white border-b px-4 py-3 flex justify-between items-center">
        <h1 className="text-xl font-bold">AI èŠå¤©åŠ©æ‰‹</h1>
        <button
          onClick={clearChat}
          className="px-4 py-2 text-sm text-gray-600 hover:text-gray-800"
        >
          æ¸…ç©ºå¯¹è¯
        </button>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4">
        {messages.length === 0 ? (
          <div className="flex items-center justify-center h-full text-gray-400">
            <p>å¼€å§‹å¯¹è¯å§ï¼</p>
          </div>
        ) : (
          <>
            {messages.map((message) => (
              <ChatMessage key={message.id} message={message} />
            ))}
            {streamingMessage && (
              <ChatMessage
                message={{
                  id: 'streaming',
                  role: 'assistant',
                  content: streamingMessage,
                  timestamp: new Date(),
                }}
                isStreaming
              />
            )}
            <div ref={messagesEndRef} />
          </>
        )}
      </div>

      {/* Input */}
      <ChatInput onSend={sendMessage} disabled={isLoading} />
    </div>
  );
}

export default App;
```

### éƒ¨ç½²

```bash
# å®‰è£…ä¾èµ–
npm install openai react-markdown

# é…ç½®ç¯å¢ƒå˜é‡
echo "VITE_OPENAI_API_KEY=your-api-key" > .env

# è¿è¡Œ
npm run dev
```

---

## é¡¹ç›®2: æ™ºèƒ½æ–‡æ¡£æ‘˜è¦

### æŠ€æœ¯æ ˆ
- Next.js + TypeScript
- OpenAI API
- PDF.js
- Tailwind CSS

### åŠŸèƒ½ç‰¹ç‚¹
- ä¸Šä¼ PDF/TXTæ–‡æ¡£
- è‡ªåŠ¨æå–å†…å®¹
- ç”Ÿæˆæ‘˜è¦
- å…³é”®è¯æå–
- å¤šç§æ‘˜è¦é•¿åº¦

### æ ¸å¿ƒä»£ç 

```typescript
// app/api/summarize/route.ts
import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import pdfParse from 'pdf-parse';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData();
    const file = formData.get('file') as File;
    const length = formData.get('length') as string; // short, medium, long
    
    // æå–æ–‡æœ¬
    let text = '';
    
    if (file.type === 'application/pdf') {
      const buffer = await file.arrayBuffer();
      const pdf = await pdfParse(Buffer.from(buffer));
      text = pdf.text;
    } else if (file.type === 'text/plain') {
      text = await file.text();
    } else {
      return NextResponse.json(
        { error: 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼' },
        { status: 400 }
      );
    }
    
    // æˆªå–å‰10000ä¸ªå­—ç¬¦ï¼ˆé¿å…è¶…tokené™åˆ¶ï¼‰
    const truncatedText = text.slice(0, 10000);
    
    // å®šä¹‰æ‘˜è¦é•¿åº¦
    const lengthMap = {
      short: '100-150å­—',
      medium: '200-300å­—',
      long: '400-500å­—',
    };
    
    // ç”Ÿæˆæ‘˜è¦
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo-16k',
      messages: [
        {
          role: 'system',
          content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£æ‘˜è¦åŠ©æ‰‹ï¼Œæ“…é•¿æå–æ–‡æ¡£æ ¸å¿ƒå†…å®¹ã€‚',
        },
        {
          role: 'user',
          content: `è¯·ä¸ºä»¥ä¸‹æ–‡æ¡£ç”Ÿæˆ${lengthMap[length]}çš„æ‘˜è¦ã€‚

è¦æ±‚ï¼š
1. ä¿ç•™æ ¸å¿ƒè§‚ç‚¹å’Œå…³é”®ä¿¡æ¯
2. ä½¿ç”¨æ¸…æ™°çš„è¯­è¨€
3. åˆ†æ®µå‘ˆç°ï¼ˆå¦‚æœå†…å®¹è¾ƒé•¿ï¼‰
4. æå–3-5ä¸ªå…³é”®è¯

æ–‡æ¡£å†…å®¹ï¼š
${truncatedText}`,
        },
      ],
      temperature: 0.5,
    });
    
    const summary = completion.choices[0].message.content;
    
    // æå–å…³é”®è¯
    const keywordsCompletion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'user',
          content: `ä»ä»¥ä¸‹æ‘˜è¦ä¸­æå–5ä¸ªå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼š\n\n${summary}`,
        },
      ],
    });
    
    const keywords = keywordsCompletion.choices[0].message.content
      ?.split(',')
      .map(k => k.trim());
    
    return NextResponse.json({
      summary,
      keywords,
      originalLength: text.length,
      summaryLength: summary?.length || 0,
    });
  } catch (error) {
    console.error('ç”Ÿæˆæ‘˜è¦å¤±è´¥:', error);
    return NextResponse.json(
      { error: 'ç”Ÿæˆæ‘˜è¦å¤±è´¥' },
      { status: 500 }
    );
  }
}
```

### å‰ç«¯é¡µé¢

```typescript
// app/page.tsx
'use client';

import { useState } from 'react';

export default function Home() {
  const [file, setFile] = useState<File | null>(null);
  const [length, setLength] = useState<'short' | 'medium' | 'long'>('medium');
  const [loading, setLoading] = useState(false);
  const [result, setResult] = useState<any>(null);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!file) return;

    setLoading(true);
    const formData = new FormData();
    formData.append('file', file);
    formData.append('length', length);

    try {
      const response = await fetch('/api/summarize', {
        method: 'POST',
        body: formData,
      });
      const data = await response.json();
      setResult(data);
    } catch (error) {
      console.error('Error:', error);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="min-h-screen bg-gray-50 py-12">
      <div className="max-w-4xl mx-auto px-4">
        <h1 className="text-4xl font-bold text-center mb-8">
          æ™ºèƒ½æ–‡æ¡£æ‘˜è¦
        </h1>

        <form onSubmit={handleSubmit} className="bg-white rounded-lg shadow-md p-6 mb-8">
          <div className="mb-4">
            <label className="block text-sm font-medium mb-2">
              ä¸Šä¼ æ–‡æ¡£ (PDF/TXT)
            </label>
            <input
              type="file"
              accept=".pdf,.txt"
              onChange={(e) => setFile(e.target.files?.[0] || null)}
              className="block w-full text-sm text-gray-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-blue-50 file:text-blue-700 hover:file:bg-blue-100"
            />
          </div>

          <div className="mb-4">
            <label className="block text-sm font-medium mb-2">
              æ‘˜è¦é•¿åº¦
            </label>
            <select
              value={length}
              onChange={(e) => setLength(e.target.value as any)}
              className="block w-full p-2 border rounded-lg"
            >
              <option value="short">ç®€çŸ­ (100-150å­—)</option>
              <option value="medium">ä¸­ç­‰ (200-300å­—)</option>
              <option value="long">è¯¦ç»† (400-500å­—)</option>
            </select>
          </div>

          <button
            type="submit"
            disabled={!file || loading}
            className="w-full py-2 px-4 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:bg-gray-300"
          >
            {loading ? 'ç”Ÿæˆä¸­...' : 'ç”Ÿæˆæ‘˜è¦'}
          </button>
        </form>

        {result && (
          <div className="bg-white rounded-lg shadow-md p-6">
            <h2 className="text-2xl font-bold mb-4">æ‘˜è¦ç»“æœ</h2>
            
            <div className="mb-4">
              <h3 className="font-semibold mb-2">å…³é”®è¯</h3>
              <div className="flex flex-wrap gap-2">
                {result.keywords?.map((keyword: string, i: number) => (
                  <span
                    key={i}
                    className="px-3 py-1 bg-blue-100 text-blue-700 rounded-full text-sm"
                  >
                    {keyword}
                  </span>
                ))}
              </div>
            </div>

            <div className="mb-4">
              <h3 className="font-semibold mb-2">æ‘˜è¦</h3>
              <p className="text-gray-700 whitespace-pre-wrap">
                {result.summary}
              </p>
            </div>

            <div className="text-sm text-gray-500">
              <p>åŸæ–‡é•¿åº¦ï¼š{result.originalLength} å­—ç¬¦</p>
              <p>æ‘˜è¦é•¿åº¦ï¼š{result.summaryLength} å­—ç¬¦</p>
              <p>å‹ç¼©æ¯”ï¼š{((result.summaryLength / result.originalLength) * 100).toFixed(1)}%</p>
            </div>
          </div>
        )}
      </div>
    </div>
  );
}
```

---

## é¡¹ç›®4: çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ

### æŠ€æœ¯æ ˆ
- Next.js + TypeScript
- LangChain
- Pinecone/ChromaDB
- OpenAI Embeddings
- RAGæ¶æ„

### ç³»ç»Ÿæ¶æ„

```
ç”¨æˆ·æé—® â†’ å‘é‡æ£€ç´¢ â†’ ç›¸å…³æ–‡æ¡£ â†’ ç»“åˆé—®é¢˜ â†’ GPTç”Ÿæˆ â†’ è¿”å›ç­”æ¡ˆ
```

### æ ¸å¿ƒå®ç°

#### 1. æ–‡æ¡£å¤„ç†

```typescript
// lib/document-processor.ts
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';
import { OpenAIEmbeddings } from 'langchain/embeddings/openai';
import { PineconeStore } from 'langchain/vectorstores/pinecone';

export async function processDocument(text: string, metadata: any) {
  // 1. åˆ†å‰²æ–‡æ¡£
  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 1000,
    chunkOverlap: 200,
  });
  
  const chunks = await splitter.createDocuments([text], [metadata]);
  
  // 2. ç”Ÿæˆå‘é‡
  const embeddings = new OpenAIEmbeddings({
    openAIApiKey: process.env.OPENAI_API_KEY,
  });
  
  // 3. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
  await PineconeStore.fromDocuments(chunks, embeddings, {
    pineconeIndex: process.env.PINECONE_INDEX,
    namespace: metadata.namespace,
  });
  
  return { chunksCount: chunks.length };
}
```

#### 2. é—®ç­”é€»è¾‘

```typescript
// lib/qa-chain.ts
import { OpenAI } from 'langchain/llms/openai';
import { RetrievalQAChain } from 'langchain/chains';
import { OpenAIEmbeddings } from 'langchain/embeddings/openai';
import { PineconeStore } from 'langchain/vectorstores/pinecone';

export async function answerQuestion(question: string, namespace: string) {
  // 1. åˆå§‹åŒ–å‘é‡å­˜å‚¨
  const embeddings = new OpenAIEmbeddings();
  const vectorStore = await PineconeStore.fromExistingIndex(embeddings, {
    pineconeIndex: process.env.PINECONE_INDEX,
    namespace,
  });
  
  // 2. åˆ›å»ºæ£€ç´¢é“¾
  const model = new OpenAI({
    temperature: 0,
    modelName: 'gpt-3.5-turbo',
  });
  
  const chain = RetrievalQAChain.fromLLM(model, vectorStore.asRetriever(4), {
    returnSourceDocuments: true,
  });
  
  // 3. æ‰§è¡ŒæŸ¥è¯¢
  const response = await chain.call({
    query: question,
  });
  
  return {
    answer: response.text,
    sources: response.sourceDocuments.map((doc: any) => ({
      content: doc.pageContent,
      metadata: doc.metadata,
    })),
  };
}
```

#### 3. APIç«¯ç‚¹

```typescript
// app/api/ask/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { answerQuestion } from '@/lib/qa-chain';

export async function POST(request: NextRequest) {
  try {
    const { question, namespace = 'default' } = await request.json();
    
    if (!question) {
      return NextResponse.json(
        { error: 'è¯·æä¾›é—®é¢˜' },
        { status: 400 }
      );
    }
    
    const result = await answerQuestion(question, namespace);
    
    return NextResponse.json(result);
  } catch (error) {
    console.error('Error:', error);
    return NextResponse.json(
      { error: 'å¤„ç†é—®é¢˜å¤±è´¥' },
      { status: 500 }
    );
  }
}
```

**æ›´å¤šé¡¹ç›®ä»£ç å’Œè¯¦ç»†å®ç°è¯·æŸ¥çœ‹é¡¹ç›®ä»“åº“...**

## ğŸ“š é¡¹ç›®èµ„æº

### ä»£ç ä»“åº“

æ‰€æœ‰é¡¹ç›®çš„å®Œæ•´ä»£ç å·²ä¸Šä¼ åˆ°ï¼š
- GitHub: [AI-Projects](https://github.com/your-username/ai-projects)
- Gitee: [AI-Projects](https://gitee.com/your-username/ai-projects)

### åœ¨çº¿æ¼”ç¤º

- é¡¹ç›®1æ¼”ç¤ºï¼š[ai-chatbot.vercel.app](https://ai-chatbot.vercel.app)
- é¡¹ç›®2æ¼”ç¤ºï¼š[doc-summarizer.vercel.app](https://doc-summarizer.vercel.app)
- é¡¹ç›®4æ¼”ç¤ºï¼š[rag-qa.vercel.app](https://rag-qa.vercel.app)

## ğŸ“ å­¦ä¹ è·¯å¾„

### æ–°æ‰‹å»ºè®®

1. **ä»é¡¹ç›®1å¼€å§‹**ï¼šAIèŠå¤©æœºå™¨äºº
   - ç†è§£åŸºæœ¬APIè°ƒç”¨
   - å­¦ä¹ æµå¼å“åº”
   - æŒæ¡çŠ¶æ€ç®¡ç†

2. **è¿›é˜¶åˆ°é¡¹ç›®2**ï¼šæ–‡æ¡£æ‘˜è¦
   - å­¦ä¹ æ–‡ä»¶å¤„ç†
   - ç†è§£æç¤ºå·¥ç¨‹
   - æŒæ¡APIè®¾è®¡

3. **æŒ‘æˆ˜é¡¹ç›®4**ï¼šçŸ¥è¯†åº“é—®ç­”
   - ç†è§£RAGæ¶æ„
   - å­¦ä¹ å‘é‡æ•°æ®åº“
   - æŒæ¡LangChain

### è¿›é˜¶å»ºè®®

1. **ç»„åˆå¤šä¸ªé¡¹ç›®**
2. **ä¼˜åŒ–æ€§èƒ½å’Œæˆæœ¬**
3. **æ·»åŠ æ›´å¤šåŠŸèƒ½**
4. **éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ**

## ä¸‹ä¸€æ­¥

- ğŸ’» [AIç¼–ç¨‹å®æˆ˜](ai/applications/coding.md)
- âœï¸ [AIå†™ä½œåº”ç”¨](ai/applications/writing.md)
- ğŸ¨ [AIè®¾è®¡å·¥å…·](ai/applications/design.md)
- ğŸ”§ [æœ€ä½³å®è·µ](ai/applications/best-practices.md)

---

?> **æç¤º**ï¼šæ‰€æœ‰é¡¹ç›®ä»£ç éƒ½ç»è¿‡æµ‹è¯•ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œã€‚å»ºè®®å…ˆç†è§£åŸç†ï¼Œå†åŠ¨æ‰‹å®è·µã€‚é‡åˆ°é—®é¢˜éšæ—¶æŸ¥çœ‹æ–‡æ¡£æˆ–åœ¨ç¤¾åŒºæé—®ï¼

